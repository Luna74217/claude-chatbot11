import json
# import numpy as np  # ì„ íƒì  import
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass, field
from collections import deque, defaultdict
import asyncio
import re
from enum import Enum
from database_manager import db_manager

# Tiktoken ëŒ€ì‹  ê°„ë‹¨í•œ í† í° ì¹´ìš´í„° (ì‹¤ì œë¡œëŠ” tiktoken ì‚¬ìš© ê¶Œì¥)
def estimate_tokens(text: str) -> int:
    """ëŒ€ëµì ì¸ í† í° ìˆ˜ ì¶”ì • (ì‹¤ì œë¡œëŠ” tiktoken ì‚¬ìš©)"""
    # ëŒ€ëµ 4ê¸€ì = 1í† í° (ì˜ì–´ ê¸°ì¤€)
    # í•œê¸€ì€ ë³´í†µ 2-3ê¸€ì = 1í† í°
    return len(text) // 3

class MemoryType(Enum):
    WORKING = "working"      # í˜„ì¬ ëŒ€í™” (ë‹¨ê¸°)
    EPISODIC = "episodic"    # ì¤‘ìš” ìˆœê°„ (ì¤‘ê¸°)
    SEMANTIC = "semantic"    # í•™ìŠµëœ ì§€ì‹ (ì¥ê¸°)
    PROCEDURAL = "procedural" # í–‰ë™ íŒ¨í„´ (ì¥ê¸°)

@dataclass
class Memory:
    """ê°œë³„ ë©”ëª¨ë¦¬ ë‹¨ìœ„"""
    id: str
    type: MemoryType
    content: str
    timestamp: datetime
    importance: float = 0.5
    access_count: int = 0
    last_accessed: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)
    embedding: Optional[List[float]] = None  # ë²¡í„° ì„ë² ë”© (ì„ íƒ)
    
    def decay_importance(self, current_time: datetime, decay_rate: float = 0.1):
        """ì‹œê°„ì— ë”°ë¥¸ ì¤‘ìš”ë„ ê°ì†Œ"""
        time_diff = (current_time - self.last_accessed).total_seconds() / 3600  # ì‹œê°„ ë‹¨ìœ„
        self.importance *= (1 - decay_rate * time_diff)
        self.importance = max(0.1, self.importance)  # ìµœì†Œê°’ ìœ ì§€

@dataclass
class ConversationContext:
    """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìŠ¤ëƒ…ìƒ·"""
    messages: List[Dict[str, str]]
    summary: Optional[str] = None
    key_points: List[str] = field(default_factory=list)
    emotional_state: Dict[str, float] = field(default_factory=dict)
    topic_stack: List[str] = field(default_factory=list)
    user_preferences: Dict[str, Any] = field(default_factory=dict)

class AdvancedContextManager:
    """ê³ ê¸‰ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 max_working_memory: int = 20,
                 max_episodic_memory: int = 100,
                 max_tokens: int = 8000,
                 compression_threshold: float = 0.7):
        
        # ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
        self.working_memory = deque(maxlen=max_working_memory)
        self.episodic_memory: List[Memory] = []
        self.semantic_memory: Dict[str, Memory] = {}
        self.procedural_memory: Dict[str, List[Dict]] = defaultdict(list)
        
        # ì„¤ì •
        self.max_episodic = max_episodic_memory
        self.max_tokens = max_tokens
        self.compression_threshold = compression_threshold
        
        # í˜„ì¬ ìƒíƒœ
        self.current_topics = []
        self.emotional_trajectory = []
        self.conversation_depth = 0
        self.last_compression = datetime.now()
        
        # íŒ¨í„´ ì¸ì‹
        self.interaction_patterns = {
            "question_types": defaultdict(int),
            "response_preferences": defaultdict(float),
            "topic_transitions": defaultdict(list)
        }
        
        # LLM ë¶„ì„ê¸° (ì„ íƒì )
        self.llm_analyzer = None
        
    async def add_interaction(self, 
                            user_message: str, 
                            ai_response: str,
                            metadata: Optional[Dict] = None,
                            session_id: str = None) -> ConversationContext:
        """ìƒˆë¡œìš´ ìƒí˜¸ì‘ìš© ì¶”ê°€ ë° ì²˜ë¦¬"""
        
        # 1. Working Memoryì— ì¶”ê°€
        interaction = {
            "timestamp": datetime.now(),
            "user": user_message,
            "assistant": ai_response,
            "metadata": metadata or {},
            "tokens": estimate_tokens(user_message + ai_response)
        }
        self.working_memory.append(interaction)
        
        # 2. ì¤‘ìš”ë„ í‰ê°€
        importance = self._calculate_importance(user_message, ai_response, metadata)
        
        # 3. ì¤‘ìš”í•œ ìˆœê°„ì€ Episodic Memoryë¡œ
        if importance > 0.7:
            await self._save_to_episodic(interaction, importance)
        
        # 4. íŒ¨í„´ í•™ìŠµ
        self._learn_patterns(user_message, ai_response)
        
        # 5. ì£¼ì œ ì¶”ì 
        self._track_topics(user_message, ai_response)
        
        # 6. ê°ì • ê¶¤ì  ì¶”ì 
        self._track_emotions(ai_response, metadata)
        
        # 7. ì»¨í…ìŠ¤íŠ¸ ì••ì¶• í•„ìš” ì—¬ë¶€ í™•ì¸
        if self._needs_compression():
            await self._compress_context()
        
        # 8. ğŸ—„ï¸ Replit Databaseì— ì»¨í…ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ ì €ì¥
        if session_id:
            memory_state = self.export_memory_state()
            db_manager.save_context_memory(session_id, memory_state)
        
        # 9. í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜
        return self._build_current_context()
    
    def _calculate_importance(self, user_msg: str, ai_response: str, metadata: Dict) -> float:
        """ìƒí˜¸ì‘ìš©ì˜ ì¤‘ìš”ë„ ê³„ì‚°"""
        importance = 0.5  # ê¸°ë³¸ê°’
        
        # ê¸¸ì´ ê¸°ë°˜ (ê¸´ ëŒ€í™”ì¼ìˆ˜ë¡ ì¤‘ìš”)
        length_factor = min(1.0, (len(user_msg) + len(ai_response)) / 1000)
        importance += length_factor * 0.2
        
        # ê°ì • ê°•ë„ (ë©”íƒ€ë°ì´í„°ì—ì„œ)
        if metadata and "emotion_score" in metadata:
            importance += metadata["emotion_score"] * 0.3
        
        # ê²½ê³„ ì¶©ëŒ (ì¤‘ìš”í•œ ìˆœê°„)
        if metadata and metadata.get("boundaries_detected", 0) > 0:
            importance += 0.3
        
        # ìƒˆë¡œìš´ ì£¼ì œ ë„ì…
        if self._is_new_topic(user_msg):
            importance += 0.2
        
        # ì§ˆë¬¸ ìœ í˜• (ì‹¬ì¸µ ì§ˆë¬¸ì¼ìˆ˜ë¡ ì¤‘ìš”)
        if any(word in user_msg.lower() for word in ["why", "how", "feel", "think"]):
            importance += 0.15
        
        return min(1.0, importance)
    
    def _is_new_topic(self, message: str) -> bool:
        """ìƒˆë¡œìš´ ì£¼ì œì¸ì§€ í™•ì¸"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP í•„ìš”
        keywords = set(message.lower().split())
        if not self.current_topics:
            return True
        
        current_keywords = set()
        for topic in self.current_topics[-3:]:  # ìµœê·¼ 3ê°œ ì£¼ì œ
            current_keywords.update(topic.lower().split())
        
        overlap = len(keywords & current_keywords) / max(len(keywords), 1)
        return overlap < 0.3
    
    async def _save_to_episodic(self, interaction: Dict, importance: float):
        """Episodic Memoryì— ì €ì¥"""
        memory = Memory(
            id=f"ep_{datetime.now().timestamp()}",
            type=MemoryType.EPISODIC,
            content=json.dumps({
                "user": interaction["user"],
                "assistant": interaction["assistant"]
            }),
            timestamp=interaction["timestamp"],
            importance=importance,
            metadata=interaction["metadata"]
        )
        
        self.episodic_memory.append(memory)
        
        # í¬ê¸° ì œí•œ ê´€ë¦¬
        if len(self.episodic_memory) > self.max_episodic:
            # ì¤‘ìš”ë„ì™€ ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ ì •ë¦¬
            self._cleanup_episodic_memory()
    
    def _cleanup_episodic_memory(self):
        """ì˜¤ë˜ë˜ê³  ëœ ì¤‘ìš”í•œ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        current_time = datetime.now()
        
        # ëª¨ë“  ë©”ëª¨ë¦¬ì˜ ì¤‘ìš”ë„ ì¬ê³„ì‚° (ì‹œê°„ ê°ì‡  ì ìš©)
        for memory in self.episodic_memory:
            memory.decay_importance(current_time)
        
        # ì¤‘ìš”ë„ ê¸°ì¤€ ì •ë ¬ í›„ í•˜ìœ„ 20% ì œê±°
        self.episodic_memory.sort(key=lambda m: m.importance, reverse=True)
        cutoff = int(self.max_episodic * 0.8)
        
        # ì œê±°ë˜ëŠ” ë©”ëª¨ë¦¬ ì¤‘ ì¼ë¶€ëŠ” Semanticìœ¼ë¡œ ì¶”ìƒí™”
        for memory in self.episodic_memory[cutoff:]:
            self._abstract_to_semantic(memory)
        
        self.episodic_memory = self.episodic_memory[:cutoff]
    
    def _abstract_to_semantic(self, memory: Memory):
        """Episodicì„ Semanticìœ¼ë¡œ ì¶”ìƒí™”"""
        try:
            content = json.loads(memory.content)
            
            # ì£¼ì œ ì¶”ì¶œ (ê°„ë‹¨í•œ êµ¬í˜„)
            topic = self._extract_topic(content["user"])
            
            # Semantic Memory ì—…ë°ì´íŠ¸
            if topic not in self.semantic_memory:
                self.semantic_memory[topic] = Memory(
                    id=f"sem_{topic}",
                    type=MemoryType.SEMANTIC,
                    content=f"User frequently discusses: {topic}",
                    timestamp=memory.timestamp,
                    importance=0.5
                )
            else:
                # ê¸°ì¡´ semantic ê°•í™”
                self.semantic_memory[topic].importance += 0.1
                self.semantic_memory[topic].access_count += 1
                
        except Exception as e:
            print(f"Semantic abstraction error: {e}")
    
    def _extract_topic(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ì œ ì¶”ì¶œ (ê°„ë‹¨í•œ êµ¬í˜„)"""
        # ì‹¤ì œë¡œëŠ” NLP ëª¨ë¸ ì‚¬ìš© ê¶Œì¥
        words = text.lower().split()
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {"the", "is", "at", "which", "on", "a", "an", "and", "or", "but"}
        keywords = [w for w in words if w not in stopwords and len(w) > 3]
        
        if keywords:
            return keywords[0]  # ê°€ì¥ ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´
        return "general"
    
    def _learn_patterns(self, user_msg: str, ai_response: str):
        """ì‚¬ìš©ì íŒ¨í„´ í•™ìŠµ"""
        # ì§ˆë¬¸ ìœ í˜• ì¶”ì 
        question_type = self._classify_question(user_msg)
        self.interaction_patterns["question_types"][question_type] += 1
        
        # ì„ í˜¸ ì‘ë‹µ ê¸¸ì´ ì¶”ì 
        response_length = len(ai_response)
        if response_length < 100:
            self.interaction_patterns["response_preferences"]["short"] += 1
        elif response_length < 500:
            self.interaction_patterns["response_preferences"]["medium"] += 1
        else:
            self.interaction_patterns["response_preferences"]["long"] += 1
    
    def _classify_question(self, text: str) -> str:
        """ì§ˆë¬¸ ë¶„ë¥˜"""
        text_lower = text.lower()
        
        if any(w in text_lower for w in ["what", "which", "who", "where", "when"]):
            return "factual"
        elif any(w in text_lower for w in ["why", "how"]):
            return "explanatory"
        elif any(w in text_lower for w in ["feel", "think", "believe", "opinion"]):
            return "subjective"
        elif "?" in text:
            return "yes_no"
        else:
            return "statement"
    
    def _track_topics(self, user_msg: str, ai_response: str):
        """ì£¼ì œ ì¶”ì """
        # í˜„ì¬ ì£¼ì œ ì¶”ì¶œ
        current_topic = self._extract_topic(user_msg)
        
        if self.current_topics and self.current_topics[-1] != current_topic:
            # ì£¼ì œ ì „í™˜ ê¸°ë¡
            self.interaction_patterns["topic_transitions"][self.current_topics[-1]].append(current_topic)
        
        self.current_topics.append(current_topic)
        
        # ìµœê·¼ 10ê°œ ì£¼ì œë§Œ ìœ ì§€
        if len(self.current_topics) > 10:
            self.current_topics = self.current_topics[-10:]
    
    def _track_emotions(self, ai_response: str, metadata: Dict):
        """ê°ì • ê¶¤ì  ì¶”ì """
        emotion_score = 0.5  # ê¸°ë³¸ê°’
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ê°ì • ì •ë³´
        if metadata and "emotion_tone" in metadata:
            emotions = metadata["emotion_tone"]
            # ê¸ì •/ë¶€ì • ì ìˆ˜ ê³„ì‚°
            positive = emotions.get("enthusiasm", 0) + emotions.get("empathy", 0)
            negative = emotions.get("hesitation", 0)
            emotion_score = 0.5 + (positive - negative) * 0.5
        
        self.emotional_trajectory.append({
            "timestamp": datetime.now(),
            "score": emotion_score
        })
        
        # ìµœê·¼ 50ê°œë§Œ ìœ ì§€
        if len(self.emotional_trajectory) > 50:
            self.emotional_trajectory = self.emotional_trajectory[-50:]
    
    def _needs_compression(self) -> bool:
        """ì••ì¶• í•„ìš” ì—¬ë¶€ í™•ì¸"""
        # í† í° ìˆ˜ ê³„ì‚°
        total_tokens = sum(item["tokens"] for item in self.working_memory)
        
        # ì‹œê°„ ê¸°ë°˜ (10ë¶„ë§ˆë‹¤)
        time_since_compression = (datetime.now() - self.last_compression).seconds > 600
        
        return total_tokens > self.max_tokens * self.compression_threshold or time_since_compression
    
    async def _compress_context(self):
        """ì»¨í…ìŠ¤íŠ¸ ì••ì¶•"""
        if len(self.working_memory) < 5:
            return  # ë„ˆë¬´ ì ìœ¼ë©´ ì••ì¶• ë¶ˆí•„ìš”
        
        # Working Memoryë¥¼ ìš”ì•½
        messages_to_compress = list(self.working_memory)[:10]  # ì˜¤ë˜ëœ 10ê°œ
        
        # ìš”ì•½ ìƒì„± (ì‹¤ì œë¡œëŠ” LLM ì‚¬ìš©)
        summary = self._generate_summary(messages_to_compress)
        
        # ì••ì¶•ëœ ë©”ëª¨ë¦¬ ìƒì„±
        compressed_memory = {
            "timestamp": messages_to_compress[0]["timestamp"],
            "user": f"[Compressed: {len(messages_to_compress)} messages]",
            "assistant": summary,
            "metadata": {"compressed": True, "original_count": len(messages_to_compress)},
            "tokens": estimate_tokens(summary)
        }
        
        # ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±°í•˜ê³  ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´
        for _ in range(len(messages_to_compress)):
            self.working_memory.popleft()
        
        self.working_memory.appendleft(compressed_memory)
        self.last_compression = datetime.now()
    
    def _generate_summary(self, messages: List[Dict]) -> str:
        """ë©”ì‹œì§€ ìš”ì•½ ìƒì„± (LLM ê¸°ë°˜)"""
        # LLM ë¶„ì„ê¸°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ìš”ì•½
        if hasattr(self, 'llm_analyzer') and self.llm_analyzer:
            try:
                # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ ìƒˆ íƒœìŠ¤í¬ ìƒì„±
                    task = asyncio.create_task(self.llm_analyzer.generate_intelligent_summary(messages))
                    # ê°„ë‹¨í•œ í´ë°±ì„ ìœ„í•´ ì¦‰ì‹œ ë°˜í™˜
                    return f"LLM ìš”ì•½ ìƒì„± ì¤‘... (ì´ì „ {len(messages)}ê°œ ëŒ€í™”)"
                else:
                    summary = loop.run_until_complete(
                        self.llm_analyzer.generate_intelligent_summary(messages)
                    )
                    return summary
            except Exception as e:
                print(f"LLM ìš”ì•½ ì˜¤ë¥˜: {e}")
                return self._generate_fallback_summary(messages)
        else:
            return self._generate_fallback_summary(messages)
    
    def _generate_fallback_summary(self, messages: List[Dict]) -> str:
        """ê¸°ë³¸ ìš”ì•½ ìƒì„± (LLM ì—†ì„ ë•Œ)"""
        key_points = []
        for msg in messages:
            if len(msg["user"]) > 50:  # ê¸´ ë©”ì‹œì§€ë§Œ
                key_points.append(f"User discussed: {msg['user'][:50]}...")
        
        if key_points:
            return f"Previous conversation covered: {'; '.join(key_points[:3])}"
        else:
            return f"Previous {len(messages)} exchanges about various topics."
    
    def _build_current_context(self) -> ConversationContext:
        """í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•"""
        # Working Memoryë¥¼ ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        messages = []
        for item in self.working_memory:
            if not item.get("metadata", {}).get("compressed", False):
                messages.append({"role": "user", "content": item["user"]})
                messages.append({"role": "assistant", "content": item["assistant"]})
            else:
                # ì••ì¶•ëœ ìš”ì•½ì€ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ
                messages.append({"role": "system", "content": item["assistant"]})
        
        # ì£¼ìš” í¬ì¸íŠ¸ ì¶”ì¶œ
        key_points = self._extract_key_points()
        
        # ê°ì • ìƒíƒœ
        emotional_state = self._calculate_emotional_state()
        
        # ì‚¬ìš©ì ì„ í˜¸ë„
        user_preferences = self._infer_preferences()
        
        return ConversationContext(
            messages=messages,
            summary=self._generate_summary(list(self.working_memory)[-5:]),
            key_points=key_points,
            emotional_state=emotional_state,
            topic_stack=self.current_topics[-5:],
            user_preferences=user_preferences
        )
    
    def _extract_key_points(self) -> List[str]:
        """ì£¼ìš” í¬ì¸íŠ¸ ì¶”ì¶œ"""
        key_points = []
        
        # ìµœê·¼ ì¤‘ìš”í•œ Episodic Memoryì—ì„œ
        recent_important = sorted(
            self.episodic_memory[-10:], 
            key=lambda m: m.importance, 
            reverse=True
        )[:3]
        
        for memory in recent_important:
            try:
                content = json.loads(memory.content)
                key_points.append(f"Important: {content['user'][:50]}...")
            except:
                pass
        
        return key_points
    
    def _calculate_emotional_state(self) -> Dict[str, float]:
        """í˜„ì¬ ê°ì • ìƒíƒœ ê³„ì‚°"""
        if not self.emotional_trajectory:
            return {"neutral": 1.0}
        
        # ìµœê·¼ ê°ì • ì ìˆ˜ì˜ í‰ê· 
        recent_scores = [e["score"] for e in self.emotional_trajectory[-10:]]
        avg_score = sum(recent_scores) / len(recent_scores)
        
        # ê°ì • ë³€í™”ìœ¨
        if len(recent_scores) > 1:
            trend = recent_scores[-1] - recent_scores[0]
        else:
            trend = 0
        
        return {
            "valence": avg_score,
            "arousal": abs(trend),
            "trend": "positive" if trend > 0 else "negative" if trend < 0 else "stable"
        }
    
    def _infer_preferences(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ë¡ """
        preferences = {}
        
        # ì„ í˜¸ ì‘ë‹µ ê¸¸ì´
        if self.interaction_patterns["response_preferences"]:
            preferred_length = max(
                self.interaction_patterns["response_preferences"].items(),
                key=lambda x: x[1]
            )[0]
            preferences["response_length"] = preferred_length
        
        # ì£¼ìš” ê´€ì‹¬ ì£¼ì œ
        if self.semantic_memory:
            top_topics = sorted(
                self.semantic_memory.items(),
                key=lambda x: x[1].importance,
                reverse=True
            )[:3]
            preferences["interests"] = [topic for topic, _ in top_topics]
        
        # ì§ˆë¬¸ ìŠ¤íƒ€ì¼
        if self.interaction_patterns["question_types"]:
            dominant_style = max(
                self.interaction_patterns["question_types"].items(),
                key=lambda x: x[1]
            )[0]
            preferences["question_style"] = dominant_style
        
        return preferences
    
    async def retrieve_relevant_context(self, query: str, max_results: int = 5) -> List[Memory]:
        """ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        relevant_memories = []
        
        # 1. Working Memoryì—ì„œ ìµœê·¼ ê´€ë ¨ í•­ëª©
        for item in list(self.working_memory)[-10:]:
            if self._is_relevant(query, item["user"] + item["assistant"]):
                relevant_memories.append(
                    Memory(
                        id="working_recent",
                        type=MemoryType.WORKING,
                        content=json.dumps(item),
                        timestamp=item["timestamp"],
                        importance=0.8
                    )
                )
        
        # 2. Episodic Memoryì—ì„œ ê´€ë ¨ í•­ëª©
        for memory in self.episodic_memory:
            if self._is_relevant(query, memory.content):
                memory.access_count += 1
                memory.last_accessed = datetime.now()
                relevant_memories.append(memory)
        
        # 3. Semantic Memoryì—ì„œ ê´€ë ¨ í•­ëª©
        query_topic = self._extract_topic(query)
        if query_topic in self.semantic_memory:
            relevant_memories.append(self.semantic_memory[query_topic])
        
        # ì¤‘ìš”ë„ ìˆœ ì •ë ¬
        relevant_memories.sort(key=lambda m: m.importance, reverse=True)
        
        return relevant_memories[:max_results]
    
    def _is_relevant(self, query: str, content: str, threshold: float = 0.3) -> bool:
        """ê´€ë ¨ì„± íŒë‹¨ (ê°„ë‹¨í•œ êµ¬í˜„)"""
        # ì‹¤ì œë¡œëŠ” ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° ê¶Œì¥
        query_words = set(query.lower().split())
        content_words = set(content.lower().split())
        
        if not query_words:
            return False
        
        overlap = len(query_words & content_words) / len(query_words)
        return overlap > threshold
    
    def get_system_prompt_context(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•  ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        context = self._build_current_context()
        
        prompt_parts = []
        
        # 1. ëŒ€í™” ìš”ì•½
        if context.summary:
            prompt_parts.append(f"Previous conversation summary: {context.summary}")
        
        # 2. ì£¼ìš” í¬ì¸íŠ¸
        if context.key_points:
            prompt_parts.append(f"Key points to remember: {'; '.join(context.key_points)}")
        
        # 3. ì‚¬ìš©ì ì„ í˜¸ë„
        if context.user_preferences:
            pref_str = ", ".join([f"{k}: {v}" for k, v in context.user_preferences.items()])
            prompt_parts.append(f"User preferences: {pref_str}")
        
        # 4. í˜„ì¬ ì£¼ì œ
        if context.topic_stack:
            prompt_parts.append(f"Current topics: {', '.join(context.topic_stack[-3:])}")
        
        # 5. ê°ì • ìƒíƒœ
        if context.emotional_state:
            emotion_str = f"valence: {context.emotional_state.get('valence', 0.5):.2f}"
            prompt_parts.append(f"Emotional context: {emotion_str}")
        
        return "\n".join(prompt_parts)
    
    def export_memory_state(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìƒíƒœ ë‚´ë³´ë‚´ê¸° (ë°±ì—…/ë¶„ì„ìš©)"""
        return {
            "timestamp": datetime.now().isoformat(),
            "working_memory": list(self.working_memory),
            "episodic_memory": [
                {
                    "id": m.id,
                    "content": m.content,
                    "importance": m.importance,
                    "timestamp": m.timestamp.isoformat()
                }
                for m in self.episodic_memory
            ],
            "semantic_memory": {
                k: {
                    "content": v.content,
                    "importance": v.importance,
                    "access_count": v.access_count
                }
                for k, v in self.semantic_memory.items()
            },
            "patterns": dict(self.interaction_patterns),
            "current_topics": self.current_topics,
            "emotional_trajectory": self.emotional_trajectory[-20:]  # ìµœê·¼ 20ê°œ
        }
    
    def import_memory_state(self, state: Dict[str, Any]):
        """ë©”ëª¨ë¦¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° (ë³µì›ìš©)"""
        try:
            # Working Memory ë³µì›
            self.working_memory.clear()
            for item in state.get("working_memory", []):
                self.working_memory.append(item)
            
            # Episodic Memory ë³µì›
            self.episodic_memory.clear()
            for item in state.get("episodic_memory", []):
                memory = Memory(
                    id=item["id"],
                    type=MemoryType.EPISODIC,
                    content=item["content"],
                    timestamp=datetime.fromisoformat(item["timestamp"]),
                    importance=item["importance"]
                )
                self.episodic_memory.append(memory)
            
            # Semantic Memory ë³µì›
            self.semantic_memory.clear()
            for topic, data in state.get("semantic_memory", {}).items():
                self.semantic_memory[topic] = Memory(
                    id=f"sem_{topic}",
                    type=MemoryType.SEMANTIC,
                    content=data["content"],
                    timestamp=datetime.now(),
                    importance=data["importance"],
                    access_count=data.get("access_count", 0)
                )
            
            # íŒ¨í„´ ë³µì›
            self.interaction_patterns = state.get("patterns", self.interaction_patterns)
            self.current_topics = state.get("current_topics", [])
            self.emotional_trajectory = state.get("emotional_trajectory", [])
            
            print("âœ… Memory state imported successfully")
            
        except Exception as e:
            print(f"âŒ Memory import error: {e}") 